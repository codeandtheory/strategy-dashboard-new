{
  "name": "Horoscope Generation Workflow",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "horoscope-generation",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [240, 300],
      "webhookId": "horoscope-generation-webhook"
    },
    {
      "parameters": {
        "resource": "chat",
        "operation": "complete",
        "model": "gpt-4o-mini",
        "options": {
          "temperature": 0.9,
          "responseFormat": {
            "type": "json_object"
          },
          "maxTokens": 600
        },
        "messages": {
          "values": [
            {
              "role": "system",
              "content": "You are a witty horoscope transformer. You take traditional horoscopes and make them irreverent and fun in the style of Co-Star. You always return valid JSON."
            },
            {
              "role": "user",
              "content": "=Transform this horoscope from Cafe Astrology into the irreverent, silly style of Co-Star. Make it witty, slightly sarcastic, and fun. Keep the core meaning but make it more casual and entertaining.\n\nOriginal horoscope for {{ $json.starSign }}:\n{{ $json.cafeAstrologyText }}\n\nReturn a JSON object with this exact structure:\n{\n  \"horoscope\": \"An irreverent, expanded version of the horoscope in Co-Star's style. Make it approximately 150 words. Keep it witty, casual, and entertaining while expanding on the themes from the original. Break it into multiple paragraphs for readability.\",\n  \"dos\": [\"Do thing 1\", \"Do thing 2\", \"Do thing 3\"],\n  \"donts\": [\"Don't thing 1\", \"Don't thing 2\", \"Don't thing 3\"]\n}\n\nMake the do's and don'ts silly, specific, and related to the horoscope content. They should be funny and slightly absurd but still relevant."
            }
          ]
        }
      },
      "id": "text-transformation",
      "name": "Create Horoscope",
      "type": "n8n-nodes-base.openAi",
      "typeVersion": 1.3,
      "position": [460, 200],
      "credentials": {
        "openAiApi": {
          "id": "openai-credentials",
          "name": "OpenAI API"
        }
      },
      "continueOnFail": false
    },
    {
      "parameters": {
        "jsCode": "// Parse OpenAI response - extract JSON from choices[0].message.content\nconst openAiOutput = $input.item.json;\nlet textResult = openAiOutput;\n\n// Extract content from OpenAI response structure\nif (openAiOutput.choices && openAiOutput.choices[0] && openAiOutput.choices[0].message) {\n  textResult = openAiOutput.choices[0].message.content;\n}\n\n// Parse JSON if it's a string\nlet parsedText = textResult;\nif (typeof textResult === 'string') {\n  try {\n    parsedText = JSON.parse(textResult);\n  } catch (e) {\n    // If parsing fails, try to extract JSON from text\n    const jsonMatch = textResult.match(/\\{[\\s\\S]*\\}/);\n    if (jsonMatch) {\n      parsedText = JSON.parse(jsonMatch[0]);\n    } else {\n      throw new Error('Could not parse text transformation response as JSON');\n    }\n  }\n}\n\n// Validate structure\nif (!parsedText.horoscope || !Array.isArray(parsedText.dos) || !Array.isArray(parsedText.donts)) {\n  throw new Error('Invalid response format from OpenAI text transformation');\n}\n\n// Store text result and pass through webhook data\n// Get webhook data from input (passed through from Create Horoscope node)\n// The input should have the original webhook data\nconst inputData = $input.item.json;\n\n// Ensure slots and reasoning are preserved as objects (not strings or flattened)\n// n8n webhook may flatten nested objects or convert them to strings, so we need to handle both\nlet slots = inputData.slots || null;\nlet reasoning = inputData.reasoning || null;\n\n// If slots/reasoning are strings, parse them as JSON\nif (slots && typeof slots === 'string') {\n  try {\n    slots = JSON.parse(slots);\n  } catch (e) {\n    console.error('Failed to parse slots as JSON:', e);\n    slots = null;\n  }\n}\n\nif (reasoning && typeof reasoning === 'string') {\n  try {\n    reasoning = JSON.parse(reasoning);\n  } catch (e) {\n    console.error('Failed to parse reasoning as JSON:', e);\n    reasoning = null;\n  }\n}\n\n// Ensure they are objects (not arrays or other types)\nif (slots && typeof slots !== 'object' || Array.isArray(slots)) {\n  slots = null;\n}\nif (reasoning && typeof reasoning !== 'object' || Array.isArray(reasoning)) {\n  reasoning = null;\n}\n\n// If slots/reasoning are not objects, try to reconstruct from flattened keys\nif (!slots && inputData) {\n  // Check if slots properties are at the top level (flattened)\n  if (inputData.style_medium_id || inputData.style_reference_id) {\n    slots = {\n      style_medium_id: inputData.style_medium_id,\n      style_reference_id: inputData.style_reference_id,\n      subject_role_id: inputData.subject_role_id,\n      subject_twist_id: inputData.subject_twist_id,\n      setting_place_id: inputData.setting_place_id,\n      setting_time_id: inputData.setting_time_id,\n      activity_id: inputData.activity_id,\n      mood_vibe_id: inputData.mood_vibe_id,\n      color_palette_id: inputData.color_palette_id,\n      camera_frame_id: inputData.camera_frame_id,\n      lighting_style_id: inputData.lighting_style_id,\n      constraints_ids: inputData.constraints_ids || (inputData['constraints_ids[0]'] ? [\n        inputData['constraints_ids[0]'],\n        inputData['constraints_ids[1]'],\n        inputData['constraints_ids[2]'],\n        inputData['constraints_ids[3]']\n      ].filter(Boolean) : [])\n    };\n  }\n}\n\nif (!reasoning && inputData) {\n  // Check if reasoning properties are at the top level (flattened)\n  if (inputData['reasoning.style_reference'] || inputData.style_reference) {\n    reasoning = {\n      style_reference: inputData['reasoning.style_reference'] || inputData.style_reference,\n      style_medium: inputData['reasoning.style_medium'] || inputData.style_medium,\n      subject_role: inputData['reasoning.subject_role'] || inputData.subject_role,\n      subject_twist: inputData['reasoning.subject_twist'] || inputData.subject_twist,\n      setting_place: inputData['reasoning.setting_place'] || inputData.setting_place,\n      setting_time: inputData['reasoning.setting_time'] || inputData.setting_time,\n      activity: inputData['reasoning.activity'] || inputData.activity,\n      mood_vibe: inputData['reasoning.mood_vibe'] || inputData.mood_vibe,\n      color_palette: inputData['reasoning.color_palette'] || inputData.color_palette,\n      camera_frame: inputData['reasoning.camera_frame'] || inputData.camera_frame,\n      lighting_style: inputData['reasoning.lighting_style'] || inputData.lighting_style,\n      constraints: inputData['reasoning.constraints'] || inputData.constraints\n    };\n  }\n}\n\nreturn {\n  json: {\n    horoscope: parsedText.horoscope,\n    dos: parsedText.dos,\n    donts: parsedText.donts,\n    imagePrompt: inputData.imagePrompt || null,\n    slots: slots,\n    reasoning: reasoning\n  }\n};"
      },
      "id": "parse-text-result",
      "name": "Parse Text Result",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [680, 200]
    },
    {
      "parameters": {
        "jsCode": "// Validate and log image prompt before sending to OpenAI\n// n8n webhook data can be in different locations depending on configuration\nconst inputData = $input.item.json;\n\nconsole.log('üìù Image prompt validation:');\nconsole.log('Input data keys:', Object.keys(inputData || {}));\nconsole.log('Full input data structure:', JSON.stringify(inputData, null, 2));\n\n// Try multiple possible locations for webhook data\n// 1. Direct in json (most common)\n// 2. In body property\n// 3. In query property\nlet webhookData = inputData;\n\n// Check if data is nested in body\nif (inputData.body && typeof inputData.body === 'object') {\n  console.log('Found data in body property');\n  webhookData = inputData.body;\n}\n// Check if data is nested in query\nelse if (inputData.query && typeof inputData.query === 'object') {\n  console.log('Found data in query property');\n  webhookData = inputData.query;\n}\n// Check if it's a string that needs parsing\nelse if (inputData.body && typeof inputData.body === 'string') {\n  try {\n    webhookData = JSON.parse(inputData.body);\n    console.log('Parsed body string to JSON');\n  } catch (e) {\n    console.warn('Could not parse body as JSON, using inputData directly');\n  }\n}\n\nconsole.log('Using webhook data from:', webhookData === inputData ? 'direct input' : 'nested property');\nconsole.log('Webhook data keys:', Object.keys(webhookData || {}));\nconsole.log('Has imagePrompt:', !!webhookData.imagePrompt);\nconsole.log('imagePrompt type:', typeof webhookData.imagePrompt);\nconsole.log('imagePrompt length:', webhookData.imagePrompt?.length || 0);\nconsole.log('imagePrompt preview:', webhookData.imagePrompt?.substring(0, 200) || 'MISSING');\n\n// Validate prompt exists and is not empty\nif (!webhookData.imagePrompt || typeof webhookData.imagePrompt !== 'string' || webhookData.imagePrompt.trim() === '') {\n  console.error('‚ùå ERROR: imagePrompt is missing or empty!');\n  console.error('Available keys in webhookData:', Object.keys(webhookData || {}));\n  console.error('Full webhook data:', JSON.stringify(webhookData, null, 2));\n  console.error('Full input data:', JSON.stringify(inputData, null, 2));\n  throw new Error('imagePrompt is missing or empty. Cannot generate image without a valid prompt. Check the webhook data structure.');\n}\n\n// Ensure prompt is a string and has minimum length\nconst prompt = String(webhookData.imagePrompt).trim();\nif (prompt.length < 10) {\n  console.error('‚ùå ERROR: imagePrompt is too short:', prompt);\n  throw new Error('imagePrompt is too short (less than 10 characters). This suggests the prompt was not built correctly.');\n}\n\nconsole.log('‚úÖ Image prompt validated successfully');\nconsole.log('Full prompt:', prompt);\n\n// Pass through all webhook data with validated prompt\n// n8n Code nodes must return an array of items\nreturn [{\n  json: {\n    ...webhookData,\n    imagePrompt: prompt\n  }\n}];"
      },
      "id": "validate-image-prompt",
      "name": "Validate Image Prompt",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [460, 300]
    },
    {
      "parameters": {
        "jsCode": "// Log what prompt is being sent to OpenAI Image Generation\nconst inputData = $input.item.json;\n\nconsole.log('üé® Preparing to send prompt to OpenAI Image Generation:');\nconsole.log('Input data keys:', Object.keys(inputData || {}));\nconsole.log('imagePrompt value:', inputData.imagePrompt);\nconsole.log('imagePrompt type:', typeof inputData.imagePrompt);\nconsole.log('imagePrompt length:', inputData.imagePrompt?.length || 0);\n\n// Validate prompt exists\nif (!inputData.imagePrompt || typeof inputData.imagePrompt !== 'string' || inputData.imagePrompt.trim() === '') {\n  console.error('‚ùå CRITICAL: imagePrompt is missing or empty when reaching OpenAI node!');\n  console.error('Full input data:', JSON.stringify(inputData, null, 2));\n  throw new Error('imagePrompt is missing when reaching OpenAI Image Generation node. Check Validate Image Prompt node output.');\n}\n\nconst prompt = String(inputData.imagePrompt).trim();\nconsole.log('‚úÖ Prompt validated - sending to OpenAI:');\nconsole.log('Full prompt:', prompt);\n\n// Pass through all data with validated prompt\nreturn [{\n  json: {\n    ...inputData,\n    imagePrompt: prompt\n  }\n}];"
      },
      "id": "log-prompt-before-openai",
      "name": "Log Prompt Before OpenAI",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [460, 350]
    },
    {
      "parameters": {
        "resource": "image",
        "operation": "create",
        "model": "dall-e-3",
        "prompt": "={{ $json['imagePrompt'] }}",
        "options": {
          "size": "1024x1024",
          "quality": "standard",
          "n": 1
        }
      },
      "id": "image-generation",
      "name": "OpenAI Image Generation",
      "type": "n8n-nodes-base.openAi",
      "typeVersion": 1.3,
      "position": [460, 450],
      "credentials": {
        "openAiApi": {
          "id": "openai-credentials",
          "name": "OpenAI API"
        }
      },
      "continueOnFail": false
    },
    {
      "parameters": {
        "jsCode": "// Extract image URL from OpenAI response before n8n converts it to a file object\n// This node runs immediately after OpenAI Image Generation (Create Avatar) to capture the URL\nconst openAiResponse = $input.item.json;\n\n// Get the input data that was sent to OpenAI (from Log Prompt Before OpenAI node)\n// Try to get it from the previous node's output\nlet inputData = {};\ntry {\n  // Try to get from the input (what OpenAI node received)\n  // OpenAI nodes sometimes pass through input data\n  inputData = $input.item.json;\n  \n  // If we can't find imagePrompt in the response, try to get it from the node reference\n  if (!inputData.imagePrompt) {\n    try {\n      const logNodeData = $('Log Prompt Before OpenAI');\n      if (logNodeData && logNodeData.item && logNodeData.item.json) {\n        inputData.imagePrompt = logNodeData.item.json.imagePrompt;\n        console.log('‚úÖ Retrieved original prompt from Log Prompt Before OpenAI node');\n      }\n    } catch (e) {\n      console.warn('Could not get prompt from Log Prompt Before OpenAI node:', e.message);\n    }\n  }\n} catch (e) {\n  console.warn('Could not get input data:', e.message);\n}\n\nconsole.log('üîç OpenAI Image Generation Response Analysis:');\nconsole.log('Response keys:', Object.keys(openAiResponse || {}));\n\n// Log the original prompt that was sent (from input)\nconsole.log('üì§ Original prompt sent to DALL-E 3:');\nconsole.log('  Prompt:', inputData.imagePrompt || 'NOT FOUND IN INPUT');\n\n// Log the revised prompt that DALL-E 3 returned\nif (openAiResponse.revised_prompt) {\n  console.log('üì• DALL-E 3 revised prompt:');\n  console.log('  Revised:', openAiResponse.revised_prompt);\n  console.log('  ‚ö†Ô∏è WARNING: DALL-E 3 completely rewrote the prompt!');\n  console.log('  Original length:', inputData.imagePrompt?.length || 0);\n  console.log('  Revised length:', openAiResponse.revised_prompt.length);\n} else if (openAiResponse.data && openAiResponse.data[0] && openAiResponse.data[0].revised_prompt) {\n  console.log('üì• DALL-E 3 revised prompt (in data array):');\n  console.log('  Revised:', openAiResponse.data[0].revised_prompt);\n  console.log('  ‚ö†Ô∏è WARNING: DALL-E 3 completely rewrote the prompt!');\n}\n\nconsole.log('Full response:', JSON.stringify(openAiResponse, null, 2));\n\nlet imageUrl = null;\n\n// Check for Create Avatar output format: { url, revised_prompt }\nif (openAiResponse.url && openAiResponse.revised_prompt) {\n  imageUrl = openAiResponse.url;\n  console.log('‚úÖ Found image URL from Create Avatar node:', imageUrl);\n}\n// OpenAI API returns: { data: [{ url: '...' }] }\nelse if (openAiResponse.data && Array.isArray(openAiResponse.data) && openAiResponse.data[0] && openAiResponse.data[0].url) {\n  imageUrl = openAiResponse.data[0].url;\n  console.log('‚úÖ Found image URL in data array:', imageUrl);\n}\n// Check if URL is in the json directly\nelse if (openAiResponse.url) {\n  imageUrl = openAiResponse.url;\n  console.log('‚úÖ Found image URL in json.url:', imageUrl);\n}\n// Check if there's a response property with the original API response\nelse if (openAiResponse.response && openAiResponse.response.data && Array.isArray(openAiResponse.response.data) && openAiResponse.response.data[0] && openAiResponse.response.data[0].url) {\n  imageUrl = openAiResponse.response.data[0].url;\n  console.log('‚úÖ Found image URL in response.data:', imageUrl);\n}\nelse {\n  console.error('‚ùå Could not find URL in OpenAI response');\n  console.error('Response structure:', JSON.stringify(openAiResponse, null, 2));\n  throw new Error('Failed to extract image URL from OpenAI Image Generation response. Response structure: ' + JSON.stringify(Object.keys(openAiResponse || {})));\n}\n\n// Get original webhook data from input\n// Note: OpenAI nodes may not pass through all input data, so we try to get what we can\nconst inputData = $input.item.json;\n\n// Ensure slots and reasoning are preserved as objects (not strings)\n// If they're not in inputData (OpenAI node might not pass them through), they'll be null\n// and we'll get them from the merged text result in Combine Results\nlet slots = inputData.slots || null;\nlet reasoning = inputData.reasoning || null;\n\n// If slots/reasoning are strings, parse them as JSON\nif (slots && typeof slots === 'string') {\n  try {\n    slots = JSON.parse(slots);\n  } catch (e) {\n    console.error('Failed to parse slots as JSON:', e);\n    slots = null;\n  }\n}\n\nif (reasoning && typeof reasoning === 'string') {\n  try {\n    reasoning = JSON.parse(reasoning);\n  } catch (e) {\n    console.error('Failed to parse reasoning as JSON:', e);\n    reasoning = null;\n  }\n}\n\n// Ensure they are objects (not arrays or other types)\nif (slots && (typeof slots !== 'object' || Array.isArray(slots))) {\n  slots = null;\n}\nif (reasoning && (typeof reasoning !== 'object' || Array.isArray(reasoning))) {\n  reasoning = null;\n}\n\n// If slots/reasoning are not objects, try to reconstruct from flattened keys (same logic as Parse Text Result)\nif (!slots && inputData) {\n  if (inputData.style_medium_id || inputData.style_reference_id) {\n    slots = {\n      style_medium_id: inputData.style_medium_id,\n      style_reference_id: inputData.style_reference_id,\n      subject_role_id: inputData.subject_role_id,\n      subject_twist_id: inputData.subject_twist_id,\n      setting_place_id: inputData.setting_place_id,\n      setting_time_id: inputData.setting_time_id,\n      activity_id: inputData.activity_id,\n      mood_vibe_id: inputData.mood_vibe_id,\n      color_palette_id: inputData.color_palette_id,\n      camera_frame_id: inputData.camera_frame_id,\n      lighting_style_id: inputData.lighting_style_id,\n      constraints_ids: inputData.constraints_ids || (inputData['constraints_ids[0]'] ? [\n        inputData['constraints_ids[0]'],\n        inputData['constraints_ids[1]'],\n        inputData['constraints_ids[2]'],\n        inputData['constraints_ids[3]']\n      ].filter(Boolean) : [])\n    };\n  }\n}\n\nif (!reasoning && inputData) {\n  if (inputData['reasoning.style_reference'] || inputData.style_reference) {\n    reasoning = {\n      style_reference: inputData['reasoning.style_reference'] || inputData.style_reference,\n      style_medium: inputData['reasoning.style_medium'] || inputData.style_medium,\n      subject_role: inputData['reasoning.subject_role'] || inputData.subject_role,\n      subject_twist: inputData['reasoning.subject_twist'] || inputData.subject_twist,\n      setting_place: inputData['reasoning.setting_place'] || inputData.setting_place,\n      setting_time: inputData['reasoning.setting_time'] || inputData.setting_time,\n      activity: inputData['reasoning.activity'] || inputData.activity,\n      mood_vibe: inputData['reasoning.mood_vibe'] || inputData.mood_vibe,\n      color_palette: inputData['reasoning.color_palette'] || inputData.color_palette,\n      camera_frame: inputData['reasoning.camera_frame'] || inputData.camera_frame,\n      lighting_style: inputData['reasoning.lighting_style'] || inputData.lighting_style,\n      constraints: inputData['reasoning.constraints'] || inputData.constraints\n    };\n  }\n}\n\n// Return the image URL along with webhook data\nreturn {\n  json: {\n    imageUrl: imageUrl,\n    imagePrompt: inputData.imagePrompt || openAiResponse.revised_prompt || null,\n    slots: slots,\n    reasoning: reasoning\n  }\n};"
      },
      "id": "extract-image-url",
      "name": "Extract Image URL",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [680, 400]
    },
    {
      "parameters": {
        "jsCode": "// This node receives merged data from both Parse Text Result and OpenAI Image Generation\n// The Merge node combines them, so we get both in $input.all()\n\n// Get all input items from the merge (should be 2: one from text path, one from image path)\nconst inputItems = $input.all();\n\nconsole.log('Number of input items:', inputItems.length);\nconsole.log('Input items:', inputItems.map(item => ({ keys: Object.keys(item.json || {}), hasBinary: !!item.binary })));\n\n// Find text result (from Parse Text Result node)\nlet textResult = null;\nlet imageOutput = null;\nlet imageItem = null;\n\nfor (const item of inputItems) {\n  const data = item.json;\n  // Text result has horoscope, dos, donts properties\n  if (data.horoscope && data.dos && data.donts) {\n    textResult = data;\n    console.log('‚úÖ Found text result');\n  }\n  // Image output - check for imageUrl from Extract Image URL node\n  else if (data.imageUrl) {\n    imageOutput = data;\n    imageItem = item;\n    console.log('‚úÖ Found image output (from Extract Image URL node)');\n  }\n  // Image output - check for url and revised_prompt (from Create Avatar/OpenAI Image Generation)\n  else if (data.url && data.revised_prompt) {\n    imageOutput = data;\n    imageItem = item;\n    console.log('‚úÖ Found image output (url + revised_prompt)');\n  }\n  // Image output - check for file object properties\n  else if (data.mimeType || data.fileType || data.fileName || data.fileSize) {\n    imageOutput = data;\n    imageItem = item;\n    console.log('‚úÖ Found image output (file object)');\n  }\n  // Image output - check for OpenAI API response format\n  else if (data.data && Array.isArray(data.data) && data.data[0] && (data.data[0].url || data.data[0].b64_json)) {\n    imageOutput = data;\n    imageItem = item;\n    console.log('‚úÖ Found image output (API response)');\n  }\n  // Image output - check for direct url property (without horoscope)\n  else if (data.url && !data.horoscope && !data.dos && !data.donts) {\n    imageOutput = data;\n    imageItem = item;\n    console.log('‚úÖ Found image output (direct url)');\n  }\n  // If it's not text result and not already identified, it might be the image\n  else if (!data.horoscope && !data.dos && !data.donts && !data.imagePrompt) {\n    imageOutput = data;\n    imageItem = item;\n    console.log('‚úÖ Found image output (fallback - not text result)');\n  }\n}\n\nif (!textResult) {\n  console.error('‚ùå Text result not found. Available items:', inputItems.map(item => Object.keys(item.json || {})));\n  throw new Error('Failed to get text result. Make sure Parse Text Result node completed successfully.');\n}\n\nif (!imageOutput) {\n  console.error('‚ùå Image output not found. Available items:', inputItems.map(item => ({ keys: Object.keys(item.json || {}), hasBinary: !!item.binary })));\n  throw new Error('Failed to get image output. Make sure OpenAI Image Generation node completed successfully. Check the execution logs to see what data was received.');\n}\n\n// Extract image URL from the merged data\n// The Extract Image URL node should have already extracted it, so check for imageUrl first\nlet imageUrl = null;\n\n// First check if imageUrl was already extracted by Extract Image URL node\nif (imageOutput.imageUrl) {\n  imageUrl = imageOutput.imageUrl;\n  console.log('‚úÖ Found image URL from Extract Image URL node');\n}\n// Check for url property (from Create Avatar/OpenAI Image Generation with revised_prompt)\nelse if (imageOutput.url) {\n  imageUrl = imageOutput.url;\n  console.log('‚úÖ Found image URL in url property:', imageUrl);\n}\n// Standard OpenAI API response format: { data: [{ url: '...' }] }\nelse if (imageOutput.data && Array.isArray(imageOutput.data) && imageOutput.data[0] && imageOutput.data[0].url) {\n  imageUrl = imageOutput.data[0].url;\n  console.log('‚úÖ Found image URL in data array');\n}\n// If it's a file object (has mimeType, fileType, etc.), check binary data for URL\nelse if (imageOutput.mimeType || imageOutput.fileType) {\n  console.error('‚ùå Image was downloaded as file object. Checking binary data for URL...');\n  \n  // Check if we can get the URL from the binary data metadata\n  if (imageItem && imageItem.binary) {\n    const binaryKeys = Object.keys(imageItem.binary);\n    if (binaryKeys.length > 0) {\n      const binaryData = imageItem.binary[binaryKeys[0]];\n      // Check various possible locations for URL in binary metadata\n      if (binaryData && binaryData.meta && binaryData.meta.url) {\n        imageUrl = binaryData.meta.url;\n        console.log('‚úÖ Found image URL in binary metadata');\n      } else if (binaryData && binaryData.data && binaryData.data.url) {\n        imageUrl = binaryData.data.url;\n        console.log('‚úÖ Found image URL in binary data');\n      }\n    }\n  }\n}\n\nif (!imageUrl) {\n  // Log the actual structure for debugging\n  console.error('Failed to extract image URL. Response structure:', Object.keys(imageOutput));\n  console.error('Full response:', JSON.stringify(imageOutput, null, 2));\n  // Also check the full item structure\n  const imageItem = inputItems.find(item => item.json.mimeType || item.json.fileType || (!item.json.horoscope && !item.json.dos));\n  if (imageItem) {\n    console.error('Full image item:', JSON.stringify(imageItem, null, 2));\n  }\n  throw new Error('Failed to extract image URL from OpenAI response. The image was downloaded as a file object without URL metadata. Please ensure Return URL is enabled in the OpenAI Image Generation node settings, or add a Code node after the OpenAI Image Generation node to extract the URL before it gets converted to a file.');\n}\n\n// Get original webhook data (imagePrompt, slots, reasoning) from the merged items\n// Try to get it from text result first (should have it from Parse Text Result)\n// Then try from image item (from Extract Image URL node)\nconst webhookData = {\n  imagePrompt: textResult?.imagePrompt || imageItem?.json?.imagePrompt || imageItem?.json?.prompt || null,\n  slots: textResult?.slots || imageItem?.json?.slots || null,\n  reasoning: textResult?.reasoning || imageItem?.json?.reasoning || null\n};\n\nconsole.log('Webhook data retrieved:', {\n  hasImagePrompt: !!webhookData.imagePrompt,\n  hasSlots: !!webhookData.slots,\n  hasReasoning: !!webhookData.reasoning,\n  slotsKeys: webhookData.slots ? Object.keys(webhookData.slots) : null\n});\n\n// Combine all results\nreturn {\n  json: {\n    horoscope: textResult.horoscope,\n    dos: textResult.dos,\n    donts: textResult.donts,\n    imageUrl: imageUrl,\n    prompt: webhookData.imagePrompt,\n    slots: webhookData.slots,\n    reasoning: webhookData.reasoning\n  }\n};"
      },
      "id": "combine-results",
      "name": "Combine Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [900, 300]
    },
    {
      "parameters": {
        "mode": "append",
        "options": {}
      },
      "id": "merge-results",
      "name": "Merge Results",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 2.1,
      "position": [680, 300]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {}
      },
      "id": "webhook-response",
      "name": "Webhook Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1.1,
      "position": [1120, 300]
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Create Horoscope",
            "type": "main",
            "index": 0
          },
          {
            "node": "Validate Image Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Validate Image Prompt": {
      "main": [
        [
          {
            "node": "OpenAI Image Generation",
            "type": "main",
            "index": 0
          }
        ]
      ],
      "error": [
        [
          {
            "node": "Webhook Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Horoscope": {
      "main": [
        [
          {
            "node": "Parse Text Result",
            "type": "main",
            "index": 0
          }
        ]
      ],
      "error": [
        [
          {
            "node": "Webhook Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Text Result": {
      "main": [
        [
          {
            "node": "Merge Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Image URL": {
      "main": [
        [
          {
            "node": "Merge Results",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "OpenAI Image Generation": {
      "main": [
        [
          {
            "node": "Extract Image URL",
            "type": "main",
            "index": 0
          }
        ]
      ],
      "error": [
        [
          {
            "node": "Webhook Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Results": {
      "main": [
        [
          {
            "node": "Combine Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Combine Results": {
      "main": [
        [
          {
            "node": "Webhook Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [],
  "triggerCount": 1,
  "updatedAt": "2024-01-01T00:00:00.000Z",
  "versionId": "1"
}


